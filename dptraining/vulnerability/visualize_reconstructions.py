from matplotlib import pyplot as plt, colors as mplcolors, ticker as mtick
from matplotlib import image as mpimg
from pathlib import Path
from numpy import linspace, load
from tqdm import tqdm, trange
from datetime import datetime
import cv2
import pandas as pd
from warnings import warn

import seaborn as sn

from argparse import ArgumentParser


calc_rero = lambda dist, thresh: 100.0 * (dist < thresh).sum(axis=0) / dist.shape[0]


def turn_axis_off(ax):
    ax.set_yticklabels([])
    ax.set_xticklabels([])
    ax.set_xticks([])
    ax.set_yticks([])
    ax.xaxis.set_major_locator(plt.NullLocator())
    ax.yaxis.set_major_locator(plt.NullLocator())
    ax.margins(x=0, y=0)


def get_metric_col(args, recon_df):
    dist_columns = {
        col_name.split("_")[-1]: col_name
        for col_name in recon_df.keys()
        if args.metric_to_use in col_name and "distance" in col_name
    }
    recon_idx_columns = {
        col_name.split("_")[-1]: col_name
        for col_name in recon_df.keys()
        if args.metric_to_use in col_name and "closest_recon" in col_name
    }
    if len(dist_columns) < 1:
        raise ValueError(
            f"Did not find any column that had {args.metric_to_use}"
            " and distance in name"
        )
    elif len(dist_columns) != len(recon_idx_columns):
        raise ValueError(
            f"Found {len(dist_columns)} columns with distances "
            f"but {len(recon_idx_columns)} with recons indices.\n"
            f"Dist: {dist_columns}\n"
            f"Idx: {recon_idx_columns}"
        )
    privacy_levels = [col.split("_")[-1] for col in dist_columns]
    privacy_levels = {
        pl: "Standard" if "Non-private" in pl else f"Îµ={float(pl.split('=')[-1]):.0E}"
        for pl in privacy_levels
    }
    return dist_columns, recon_idx_columns, privacy_levels


def get_min_values_over_multiple_columns(
    data_frame: pd.DataFrame, columns: list[str], N: int, min_mode: bool = True
) -> pd.DataFrame:
    data_frame = data_frame[list(columns.values())]
    stacked = data_frame.stack()

    # Sort the stacked values and get the N lowest values
    if min_mode:
        extreme_values = stacked.nsmallest(N)
    else:
        extreme_values = stacked.nlargest(N)

    # Get the indices of the N lowest values
    indices = extreme_values.index

    # Retrieve the row and column names from the indices
    row_indices = indices.get_level_values(0)
    column_names = indices.get_level_values(1)

    # Create a DataFrame to show the coordinates of the lowest values
    coordinates_df = pd.DataFrame(
        {"Row": row_indices, "Column": column_names, "Value": extreme_values.values}
    )
    return coordinates_df


def load_img(args, path):
    if args.multi_dim_input:
        img = load(path, allow_pickle=True, fix_imports=False)
        img = img[..., img.shape[-1] // 2].squeeze()
        return img
    else:
        return mpimg.imread(path)


if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument(
        "--recon_csv",
        type=Path,
        default=None,
        required=True,
        help="Path to csv file with distance information",
    )
    parser.add_argument(
        "--metric_to_use",
        type=str,
        default="lpips",
        help="Name of distance metric used",
    )
    parser.add_argument(
        "-ni",
        "--N_images",
        default=5,
        help="How many images to visualize in summary",
        type=int,
    )
    parser.add_argument(
        "--font_scale",
        type=float,
        default=2.8,
        help="font scale for figures",
    )
    parser.add_argument(
        "--multi_dim_input",
        action="store_true",
        help="Ground truth and reconstructions are arrays with > 2 dimensions "
        "and saved in npy files. We assume all arrays have the same shape!",
    )
    args = parser.parse_args()

    sn.set_theme(
        context="notebook",
        style="white",
        font="Times New Roman",
        font_scale=args.font_scale,
        palette="viridis",
    )
    sn.despine()
    sn.set(rc={"figure.figsize": (12, 12)}, font_scale=args.font_scale)
    colors = {
        "red": "firebrick",
        "blue": "steelblue",
        "green": "forestgreen",
        "purple": "darkorchid",
        "orange": "darkorange",
        "gray": "lightslategray",
        "black": "black",
    }

    recon_df = pd.read_csv(args.recon_csv)

    cmap = plt.cm.Dark2
    cmaplist = [cmap(i) for i in range(cmap.N)]

    dist_columns, idx_columns, privacy_levels = get_metric_col(args, recon_df)
    best_recons = get_min_values_over_multiple_columns(
        recon_df, dist_columns, args.N_images
    )
    privacy_levels = dict(sorted(privacy_levels.items()))
    base_path = Path(recon_df["gt_image"].iloc[0]).parent.parent.parent
    save_dir = Path(args.recon_csv.parent) / args.metric_to_use
    save_dir.mkdir(exist_ok=True)
    file_extension = "npy" if args.multi_dim_input else "png"

    inches_per_img = 2
    fig, axs = plt.subplots(
        args.N_images,
        len(privacy_levels) + 1,
        figsize=(
            (len(privacy_levels) + 1) * inches_per_img,
            args.N_images * inches_per_img,
        ),
        sharex=True,
        sharey=True,
        # constrained_layout=True,
        gridspec_kw={"wspace": 0, "hspace": 0},
    )
    for ax in axs:
        for a in ax:
            turn_axis_off(a)
    for img_num, (_, best_row) in tqdm(
        enumerate(best_recons.iterrows()), leave=False, desc="build figure"
    ):
        best_row_num = best_row["Row"]
        recon_row = recon_df.iloc[best_row_num]
        gt_path = Path(recon_row["gt_image"])
        batch = gt_path.parent.stem
        gt_img = load_img(args, gt_path)
        plt_kwargs = {}
        if len(gt_img.shape) == 2:
            plt_kwargs["cmap"] = "gray"
        axs[img_num, 0].imshow(gt_img, **plt_kwargs)
        for pl_num, (pl_raw, pl_formatted) in enumerate(privacy_levels.items()):
            pl_name = pl_raw
            try:
                float(pl_name)
                pl_name = f"eps={pl_name}"
            except:
                pass
            recon_path = (
                base_path
                / pl_name
                / str(batch)
                / f"{recon_row[idx_columns[pl_raw]]}.{file_extension}"
            )
            assert recon_path.is_file(), f"file not found: {recon_path}"
            recon_img_data = load_img(args, recon_path)
            axs[img_num, pl_num + 1].imshow(recon_img_data, **plt_kwargs)
            if img_num == 0:
                axs[0, pl_num + 1].set_title(pl_formatted)
    axs[0, 0].set_title("Original")
    fig.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)

    fig2, ax2 = plt.subplots(1, 1, figsize=(5, 5))
    dist_metric_name: str
    ax2.set_xlabel(args.metric_to_use)
    # ax2[1].set_xlabel("Mean squared distance")
    ax2.set_ylabel("Images within distance")
    ax2.yaxis.set_major_formatter(mtick.PercentFormatter())
    for pl_num, ((pl, dist_col), color) in tqdm(
        enumerate(zip(dist_columns.items(), cmaplist)),
        total=len(dist_columns),
        desc="building figures",
        leave=False,
    ):
        dist = recon_df[dist_col].sort_values()
        y = 100.0 * linspace(0, dist.shape[0], num=dist.shape[0]) / dist.shape[0]
        ax2.step(dist, y, label=privacy_levels[pl], color=color)
    fig2.legend(loc="upper left", bbox_to_anchor=(0.12, 0.89))

    fig.savefig(
        str(save_dir / "reconstructions_ordered.pdf"), dpi=300, bbox_inches="tight"
    )
    fig.savefig(
        str(save_dir / "reconstructions_ordered.png"), dpi=300, bbox_inches="tight"
    )
    fig.savefig(str(save_dir / "reconstructions_ordered.svg"), bbox_inches="tight")
    fig2.savefig(
        str(save_dir / "characteristic_rero_curve.pdf"), dpi=300, bbox_inches="tight"
    )
    fig2.savefig(
        str(save_dir / "characteristic_rero_curve.png"), dpi=300, bbox_inches="tight"
    )
    fig2.savefig(str(save_dir / "characteristic_rero_curve.svg"), bbox_inches="tight")
