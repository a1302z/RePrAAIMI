from argparse import ArgumentParser
from pathlib import Path
from typing import Callable

import numpy as np
import pandas as pd
import piq
import torch
from jax import numpy as jn
from torch.utils.data import DataLoader, Dataset
from torchvision.datasets.folder import default_loader
from torchvision.transforms import ToTensor
from tqdm import tqdm, trange

parser = ArgumentParser()
parser.add_argument(
    "--recon_folder",
    type=Path,
    default=None,
    help="Folder with reconstructions",
)
parser.add_argument(
    "--jax_threshold",
    type=float,
    default=1e10,
    help="Use iterative jax implementation to calculate L2 distance between vectors above this threshold",
)
args = parser.parse_args()


def flatten_features(ftrs):
    return np.stack(
        [np.concatenate([v.flatten().cpu().numpy() for v in d.values()]) for d in ftrs],
        axis=0,
    )


calc_rero = lambda dist, thresh: 100.0 * (dist < thresh).sum(axis=0) / dist.shape[0]


def mean_diff_jax_alongX(a1: jn.DeviceArray, a2: jn.DeviceArray):
    X, N = a1.shape
    X1, M = a2.shape
    assert X == X1
    out = jn.zeros((N, M))
    for l, r in tqdm(zip(a1, a2), total=X, leave=False):
        out += jn.square(l[:, None] - r)
    out /= X
    return out


def mean_diff_np_alongNX(a1, a2, patchsize=1000):
    N, X = a1.shape
    M, X1 = a2.shape
    assert X == X1
    out = np.zeros((N, M))
    a1 = a1.T.copy()
    a2 = jn.array(a2.T.copy())
    N_patches = N // patchsize + (N % patchsize > 0) * 1
    for i in trange(N_patches, leave=False, desc="Distance patches"):
        patch = jn.array(a1[:, i * patchsize : (i + 1) * patchsize])
        out[i * patchsize : (i + 1) * patchsize] = np.array(
            mean_diff_jax_alongX(patch, a2)
        )
        del patch
    return out


def calc_perc_dist_direct(features_gt, features_rec):
    return torch.pow(features_gt[:, None, ...] - features_rec, 2).mean(dim=2).cpu()


def mean_diff_torch_alongX(a1: torch.Tensor, a2: torch.Tensor):
    X, N = a1.shape
    X1, M = a2.shape
    assert X == X1
    out = torch.zeros((N, M), device=a1.device)
    for l, r in tqdm(zip(a1, a2), total=X, leave=False):
        out += torch.square(l[:, None] - r)
    out /= X
    return out


def mean_diff_torch_alongNX(
    a1: torch.Tensor,
    a2: torch.Tensor,
    patchsize=1000,
    device=torch.device("cuda" if torch.cuda.is_available() else "cpu"),
):
    N, X = a1.shape
    M, X1 = a2.shape
    assert X == X1
    out = torch.zeros((N, M))
    a1 = a1.T.clone().to(device)
    a2 = a2.clone().to(device)
    N_patches = N // patchsize + (N % patchsize > 0) * 1
    for i in trange(N_patches, leave=False, desc="Distance patches"):
        patch = a1[:, i * patchsize : (i + 1) * patchsize].T.clone()
        # out[i * patchsize : (i + 1) * patchsize] = mean_diff_torch_alongX(
        #     patch, a2
        # ).cpu()
        out[i * patchsize : (i + 1) * patchsize] = calc_perc_dist_direct(
            patch, a2
        ).cpu()
        del patch
    return out


read_directory = Path(args.recon_folder)
privacy_level_dirs = {
    d.stem.replace("eps=", ""): d for d in read_directory.iterdir() if d.is_dir()
}
privacy_level_dirs = dict(sorted(privacy_level_dirs.items()))
gt_folder = privacy_level_dirs["gt"]
assert gt_folder.is_dir()
del privacy_level_dirs["gt"]
batches = [int(d.stem) for d in gt_folder.iterdir() if d.is_dir()]
batches = max(batches)


def calc_mse_diff(
    args,
    features_gt,
    features_rec,
    device=torch.device("cuda" if torch.cuda.is_available() else "cpu"),
):
    N, M, X = features_gt.shape[0], features_rec.shape[0], features_gt.shape[1]
    if (
        N * M * X < args.jax_threshold
    ):  # this is just an empirical threshold and strongly depends on the hardware
        perc_dist = calc_perc_dist_direct(
            features_gt.to(device), features_rec.to(device)
        )
    else:  # memory optimised version
        perc_dist = mean_diff_torch_alongNX(
            features_rec,
            features_gt,
            int(args.jax_threshold / np.prod(features_rec.shape)),
        )

    min_dist, closest_recon_to_gt = torch.min(perc_dist, dim=0)[0], torch.argmin(
        perc_dist, dim=0
    )
    return min_dist, closest_recon_to_gt


def get_indices_of_values(larger_array, smaller_array):
    indices = []
    for value in smaller_array:
        matching_indices = np.where(larger_array == value)[0]
        indices.append(matching_indices)
    return np.concatenate(indices)


class FolderDataset(Dataset):
    def __init__(
        self,
        folder_path: Path,
        loader_fn: Callable = default_loader,
        transform: Callable = torch.nn.Identity(),
    ) -> None:
        super().__init__()
        self.files = [f for f in folder_path.iterdir() if f.is_file()]
        self.loader_fn = loader_fn
        self.transform = transform

    def __len__(self) -> int:
        return len(self.files)

    def __getitem__(self, index) -> torch.Tensor:
        return self.transform(self.loader_fn(self.files[index]))


def collate_fn(batch_list: list[torch.Tensor]) -> dict[str, torch.Tensor]:
    return {"images": torch.stack(batch_list, dim=0)}


N_WORKER = 2
BATCH_SIZE = 1024
PREFETCH_FACTOR = 4
fid_metric = piq.FID()
lpips_metric = piq.ContentLoss(
    layers=("relu4_3", "relu5_3"),
    weights=(1.0, 1.0),
    normalize_features=True,
)  # full lpips exceeds all memory budgets we have
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

results_dict = {
    "batch_id": [],
    "gt_image": [],
    **{
        f"closest_recon_fid_{privacy_level}": []
        for privacy_level in privacy_level_dirs.keys()
    },
    **{
        f"recon_distance_fid_{privacy_level}": []
        for privacy_level in privacy_level_dirs.keys()
    },
    **{
        f"closest_recon_lpips_{privacy_level}": []
        for privacy_level in privacy_level_dirs.keys()
    },
    **{
        f"recon_distance_lpips_{privacy_level}": []
        for privacy_level in privacy_level_dirs.keys()
    },
}
for batch_num in trange(batches, desc="Batches", leave=False):
    # gt_data = load_data(gt_folder, batch_num)
    gt_batch_path = gt_folder / str(batch_num)
    gt_dataset = FolderDataset(
        gt_batch_path,
        transform=ToTensor(),
    )
    gt_loader = DataLoader(
        gt_dataset,
        collate_fn=collate_fn,
        num_workers=N_WORKER,
        batch_size=BATCH_SIZE,
        pin_memory=False,
        prefetch_factor=PREFETCH_FACTOR,
    )
    lpips_metric.to(device)
    with torch.inference_mode():
        gt_fid_features = fid_metric.compute_feats(gt_loader)
        gt_lpips_features = torch.concatenate(
            [
                torch.concatenate(
                    [
                        x_i.cpu().flatten(1)
                        for x_i in lpips_metric.get_features(x["images"].to(device))
                    ],
                    dim=1,
                )
                for x in tqdm(gt_loader, desc="GT lpips feats", leave=False)
            ],
            dim=0,
        )

    assert np.isnan(gt_lpips_features).sum() == 0

    batch_dict = {
        "batch_id": [batch_num for _ in range(len(gt_loader.dataset))],
        "img_id": list(range(len(gt_loader.dataset))),
        "gt_image": [gt_batch_path / f"{i}.png" for i in range(len(gt_loader.dataset))],
    }

    for privacy_level, recon_folder in tqdm(
        privacy_level_dirs.items(),
        total=len(privacy_level_dirs),
        desc="Privacy Levels",
        leave=False,
    ):
        recon_batch_path = recon_folder / str(batch_num)
        recon_loader = DataLoader(
            FolderDataset(
                recon_batch_path,
                transform=ToTensor(),
            ),
            collate_fn=collate_fn,
            num_workers=N_WORKER,
            batch_size=BATCH_SIZE,
            pin_memory=False,
            prefetch_factor=PREFETCH_FACTOR,
        )

        with torch.inference_mode():
            lpips_metric.to(device)
            recon_fid_features = fid_metric.compute_feats(recon_loader)
            recon_lpips_features = torch.concatenate(
                [
                    torch.concatenate(
                        [
                            x_i.cpu().flatten(1)
                            for x_i in lpips_metric.get_features(x["images"].to(device))
                        ],
                        dim=1,
                    )
                    for x in tqdm(recon_loader, desc="Recon lpips feats", leave=False)
                ],
                dim=0,
            )
            assert np.isnan(recon_lpips_features).sum() == 0

            lpips_metric.to("cpu")
            torch.cuda.empty_cache()
            min_dist_fid, closest_recon_to_gt_fid = calc_mse_diff(
                args, gt_fid_features, recon_fid_features
            )
            torch.cuda.empty_cache()
            min_dist_lpips, closest_recon_to_gt_lpips = calc_mse_diff(
                args, gt_lpips_features, recon_lpips_features
            )
            ssims = torch.zeros((len(gt_dataset), len(recon_loader.dataset)))
            mses = torch.zeros((len(gt_dataset), len(recon_loader.dataset)))
            for i, gt_img in tqdm(
                enumerate(gt_dataset),
                total=len(gt_dataset),
                desc="calc traditional metrics",
                leave=False,
            ):
                gt_img = gt_img.to(device)
                for j, batch in tqdm(
                    enumerate(recon_loader), total=len(recon_loader), leave=False
                ):
                    batch = batch["images"].to(device)
                    expanded_img = gt_img.expand(batch.shape)
                    ssims[i, j * BATCH_SIZE : (j + 1) * BATCH_SIZE] = piq.ssim(
                        x=expanded_img,
                        y=batch,
                        reduction="none",
                    ).cpu()
                    mses[
                        i, j * BATCH_SIZE : (j + 1) * BATCH_SIZE
                    ] = torch.nn.functional.mse_loss(
                        expanded_img, batch, reduction="none"
                    ).sum(
                        dim=list(range(1, len(batch.shape)))
                    )
            closest_recon_to_gt_ssim = ssims.argmax(dim=1)
            best_ssim = ssims.max(dim=1)[0]
            closest_recon_to_gt_mse = mses.argmin(dim=1)
            min_dist_mse = mses.min(dim=1)[0]

        batch_dict[
            f"closest_recon_fid_{privacy_level}"
        ] = closest_recon_to_gt_fid.flatten().tolist()
        batch_dict[
            f"recon_distance_fid_{privacy_level}"
        ] = min_dist_fid.flatten().tolist()
        batch_dict[
            f"closest_recon_lpips_{privacy_level}"
        ] = closest_recon_to_gt_lpips.flatten().tolist()
        batch_dict[
            f"recon_distance_lpips_{privacy_level}"
        ] = min_dist_lpips.flatten().tolist()
        batch_dict[
            f"closest_recon_ssim_{privacy_level}"
        ] = closest_recon_to_gt_ssim.flatten().tolist()
        batch_dict[f"best_ssim_{privacy_level}"] = best_ssim.flatten().tolist()
        batch_dict[
            f"closest_recon_mse_{privacy_level}"
        ] = closest_recon_to_gt_mse.flatten().tolist()
        batch_dict[
            f"recon_distance_fid_{privacy_level}"
        ] = min_dist_mse.flatten().tolist()
    for key, value in results_dict.items():
        results_dict[key] += batch_dict[key]


total_df = pd.DataFrame.from_dict(results_dict)
total_df.to_csv(str(read_directory / "perceptual_distances.csv"))
