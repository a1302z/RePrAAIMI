from scipy.stats import norm, chi2, ncx2
import numpy as np
from scipy.integrate import quad
from scipy.optimize import fsolve
from functools import partial
from sympy.stats import ChiSquared, density
import sympy as sy


def dens_func_P(x, sigma):
    return chi2(df=1, scale=sigma**2).pdf(x)


def Q(x, Delta, sigma):
    return ncx2(df=1, nc=Delta**2 / sigma**2, scale=sigma**2).pdf(x)


def dens_func_Q(x, Delta, sigma, p):
    return p * Q(x, Delta, sigma) + (1 - p) * dens_func_P(x, sigma)


def make_llr_func():
    x = sy.Symbol("x", real=True)
    Delta, sigma, p = sy.symbols("Delta, sigma, p", positive=True)
    P = density(ChiSquared("", 1))(x / sigma**2) / (sigma**2)
    k = 1
    lamda = Delta**2 / sigma**2
    y = x / sigma**2
    f = (0.5 * sy.exp(-(lamda + y) / 2) * (y / lamda) ** ((k - 2) / 4)) * sy.besseli(
        (k - 2) / 2, sy.sqrt(lamda * y)
    )
    Q = f / sigma**2
    mixture = p * Q + (1 - p) * P
    expr = sy.log(mixture / P)
    g = sy.lambdify((x, Delta, sigma, p), expr, modules="mpmath")
    return lambda x, Delta, sigma, p: float(g(x, Delta, sigma, p))


log_likelihood_ratio_func = make_llr_func()


def compute_moments(llr, density):
    """Compute moments up to order 5"""
    moments = [0] * 5
    for i in range(5):
        ord = i + 1
        integrand = lambda x: llr(x) ** ord * density(x)
        moments[i], _ = quad(integrand, 0, np.inf)
    return np.array(moments)


def compute_cumulants(moments):
    """Compute cumulants up to order 5"""
    kappas = [0] * 5
    kappas[0] = moments[0]
    kappas[1] = moments[1] - moments[0] ** 2
    kappas[2] = moments[2] - 3 * moments[1] * moments[0] + 2 * moments[0] ** 3
    kappas[3] = (
        moments[3]
        - 4 * moments[2] * moments[0]
        - 3 * moments[1] ** 2
        + 12 * moments[1] * moments[0] ** 2
        - 6 * moments[0] ** 4
    )
    kappas[4] = (
        moments[4]
        - 5 * moments[3] * moments[0]
        - 10 * moments[2] * moments[1]
        + 20 * moments[2] * moments[0] ** 2
        + 30 * moments[1] ** 2 * moments[0]
        - 60 * moments[1] * moments[0] ** 3
        + 24 * moments[0] ** 5
    )
    return np.array(kappas)


def compute_correction_factor(x, cumulants):
    "Compute correction factor for a distribution at x given its cumulants"
    inv_sigma_n = 1.0 / np.sqrt(cumulants[1])
    kap_3 = cumulants[2]
    kap_4 = cumulants[3]
    kap_5 = cumulants[4]
    expansion = -1.0 / 6.0 * inv_sigma_n**3 * kap_3 * (x**2 - 1.0)
    expansion -= 1.0 / 24.0 * inv_sigma_n**4 * kap_4 * (
        x**3 - 3 * x
    ) + 1.0 / 72.0 * inv_sigma_n**6 * kap_3**2 * (x**5 - 10 * x**3 + 15 * x)
    expansion -= (
        1.0 / 120.0 * inv_sigma_n**5 * kap_5 * (x**4 - 6 * x**2 + 3)
        + 1.0
        / 144.0
        * inv_sigma_n**7
        * kap_3
        * kap_4
        * (x**6 - 15 * x**4 + 45 * x**2 - 15)
        + 1.0
        / 1296.0
        * inv_sigma_n**9
        * kap_3**3
        * (x**8 - 28 * x**6 + 210 * x**4 - 420 * x**2 + 105)
    )
    return expansion * norm.pdf(x)


def approx_quantile(alpha, cumulants):
    def f(x):
        return norm.cdf(x) + compute_correction_factor(x, cumulants) - alpha

    return fsolve(f, x0=norm.ppf(alpha))


def rero_bound_glrt(kappa, sigma, Delta, sampling_rate, N_steps):
    assert N_steps >= 30
    moments_p = compute_moments(
        partial(log_likelihood_ratio_func, Delta=Delta, sigma=sigma, p=sampling_rate),
        partial(dens_func_P, sigma=sigma),
    )
    moments_q = compute_moments(
        partial(log_likelihood_ratio_func, Delta=Delta, sigma=sigma, p=sampling_rate),
        partial(dens_func_Q, Delta=Delta, sigma=sigma, p=sampling_rate),
    )
    cumulants_p = compute_cumulants(moments_p)
    cumulants_q = compute_cumulants(moments_q)
    mu = np.sqrt(N_steps) * ((moments_q[0] - moments_p[0]) / np.sqrt(cumulants_p[1]))
    cumulants_p *= N_steps
    cumulants_q *= N_steps
    h = approx_quantile(1 - kappa, cumulants_p)
    x = h - mu
    if cumulants_p[1] != cumulants_q[1]:
        x *= np.sqrt(cumulants_p[1] / cumulants_q[1])
    normal_cdf_x = norm.cdf(x)
    corr = compute_correction_factor(x, cumulants_q)
    return 1 - np.minimum(1.0, np.maximum(0, normal_cdf_x + corr))
