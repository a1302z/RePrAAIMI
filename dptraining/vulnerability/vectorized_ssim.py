from typing import Tuple, Union, List, Optional
import torch
import torch.nn.functional as F
from tqdm import trange, tqdm
from piq.functional import gaussian_filter


def simple_3d_slicewise_distances(x, y, dist_fn, *args, **kwargs):
    out = torch.zeros((x.shape[0], y.shape[0]))
    for i, x_i in tqdm(
        enumerate(x), total=x.shape[0], leave=False, desc="calc 3d distances"
    ):
        for j, y_j in tqdm(enumerate(y), total=y.shape[0], leave=False):
            out[i, j] = dist_fn(x_i, y_j, *args, **kwargs)
    return out


def vectorized_all_vs_all_2d_ssim(
    x: torch.Tensor,
    y: torch.Tensor,
    kernel_size: int = 11,
    kernel_sigma: float = 1.5,
    data_range: Union[int, float] = 1.0,
    reduction: str = "mean",
    full: bool = False,
    downsample: bool = True,
    k1: float = 0.01,
    k2: float = 0.03,
    patchsize=100,
) -> List[torch.Tensor]:
    assert kernel_size % 2 == 1, f"Kernel size must be odd, got [{kernel_size}]"
    _validate_input([x, y], dim_range=(4, 5), data_range=(0, data_range))
    with torch.inference_mode():
        x = x / float(data_range)
        y = y / float(data_range)

        # Averagepool image if the size is large enough
        f = max(1, round(min(x.size()[-2:]) / 256))
        if (f > 1) and downsample:
            x = F.avg_pool2d(x, kernel_size=f)
            y = F.avg_pool2d(y, kernel_size=f)

        kernel = gaussian_filter(
            kernel_size, kernel_sigma, device=x.device, dtype=x.dtype
        ).repeat(x.size(1), 1, 1, 1)
        ssim_val, _ = _ssim_per_channel(
            x=x,
            y=y,
            kernel=kernel,
            data_range=data_range,
            k1=k1,
            k2=k2,
            patchsize=patchsize,
        )

    return ssim_val


def _ssim_per_channel(
    x: torch.Tensor,
    y: torch.Tensor,
    kernel: torch.Tensor,
    data_range: Union[float, int] = 1.0,
    k1: float = 0.01,
    k2: float = 0.03,
    patchsize=100,
) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:
    r"""Calculate Structural Similarity (SSIM) index for X and Y per channel.

    Args:
        x: An input tensor. Shape :math:`(N, C, H, W)`.
        y: A target tensor. Shape :math:`(N, C, H, W)`.
        kernel: 2D Gaussian kernel.
        data_range: Maximum value range of images (usually 1.0 or 255).
        k1: Algorithm parameter, K1 (small constant, see [1]).
        k2: Algorithm parameter, K2 (small constant, see [1]).
            Try a larger K2 constant (e.g. 0.4) if you get a negative or NaN results.

    Returns:
        Full Value of Structural Similarity (SSIM) index.
    """
    if x.size(-1) < kernel.size(-1) or x.size(-2) < kernel.size(-2):
        raise ValueError(
            f"Kernel size can't be greater than actual input size. "
            f"Input size: {x.size()}. Kernel size: {kernel.size()}"
        )

    c1 = k1**2
    c2 = k2**2
    n_channels = x.size(1)
    mu_x = F.conv2d(x, weight=kernel, stride=1, padding=0, groups=n_channels)
    mu_y = F.conv2d(y, weight=kernel, stride=1, padding=0, groups=n_channels)

    mu_xx = mu_x**2
    mu_yy = mu_y**2
    sigma_xx = (
        F.conv2d(x**2, weight=kernel, stride=1, padding=0, groups=n_channels) - mu_xx
    )
    # sigma_xx = sigma_xx.view(sigma_xx.shape[0], 1, *sigma_xx.shape[1:])
    # mu_xx = mu_xx.view(mu_xx.shape[0], 1, *mu_xx.shape[1:])

    sigma_xx.add_(c2)
    sigma_yy = (
        F.conv2d(y**2, weight=kernel, stride=1, padding=0, groups=n_channels) - mu_yy
    )

    N = y.shape[0]
    N_patches = N // patchsize + (N % patchsize > 0) * 1
    ssim_val = torch.zeros((x.shape[0], y.shape[0]), dtype=x.dtype, device="cpu")
    for patch_num in trange(N_patches, desc="calc ssim", leave=False):
        y_i = y[patch_num * patchsize : (patch_num + 1) * patchsize]
        mu_xy_i = (
            mu_x.view(mu_x.shape[0], 1, *mu_x.shape[1:])
            * mu_y[patch_num * patchsize : (patch_num + 1) * patchsize]
        )
        mu_xy_i = mu_xy_i.view(-1, *mu_xy_i.shape[2:])

        # mu_xy_i = mu_xy[:, patch_num * patchsize : (patch_num + 1) * patchsize].reshape(
        #     -1, *mu_xy.shape[2:]
        # )

        sigma_xy = (x.view(x.shape[0], 1, *x.shape[1:]) * y_i).view(-1, *x.shape[1:])
        sigma_xy = (
            F.conv2d(sigma_xy, weight=kernel, stride=1, padding=0, groups=n_channels)
            - mu_xy_i
        )
        sigma_xy = sigma_xy.view(x.shape[0], y_i.shape[0], *sigma_xy.shape[1:])
        mu_xy_i = mu_xy_i.view(x.shape[0], y_i.shape[0], *mu_xy_i.shape[1:])

        # Contrast sensitivity (CS) with alpha = beta = gamma = 1.
        sigma_xy.mul_(2.0)
        sigma_xy.add_(c2)
        sigma_xx_i = sigma_xx.view(sigma_xx.shape[0], 1, *sigma_xx.shape[1:]).add(
            sigma_yy[patch_num * patchsize : (patch_num + 1) * patchsize]
        )
        sigma_xx_i.pow_(-1.0)
        sigma_xx_i.mul_(sigma_xy)
        # cs = sigma_xy / sigma_xx_i
        cs = sigma_xx_i

        # (2.0 * mu_xy_i + c1)
        mu_xy_i.mul_(2.0)
        mu_xy_i.add_(c1)
        mu_yy_i = mu_xx.view(mu_xx.shape[0], 1, *mu_xx.shape[1:]).add(
            +mu_yy[patch_num * patchsize : (patch_num + 1) * patchsize]
        )
        mu_yy_i.add_(c1)
        mu_xy_i.div_(mu_yy_i)
        mu_xy_i.mul_(cs)
        ss = mu_xy_i

        ssim_val[:, patch_num * patchsize : (patch_num + 1) * patchsize] = ss.mean(
            dim=(-1, -2, -3)
        ).cpu()
        del mu_xy_i, sigma_xx_i, y_i, sigma_xy
        torch.cuda.empty_cache()
    return ssim_val, None


def _validate_input(
    tensors: List[torch.Tensor],
    dim_range: Tuple[int, int] = (0, -1),
    data_range: Tuple[float, float] = (0.0, -1.0),
    size_range: Optional[Tuple[int, int]] = None,
    check_for_channels_first: bool = False,
) -> None:
    r"""Check that input(-s)  satisfies the requirements
    Args:
        tensors: Tensors to check
        dim_range: Allowed number of dimensions. (min, max)
        data_range: Allowed range of values in tensors. (min, max)
        size_range: Dimensions to include in size comparison. (start_dim, end_dim + 1)
    """

    if not __debug__:
        return

    x = tensors[0]

    for t in tensors:
        assert torch.is_tensor(t), f"Expected torch.Tensor, got {type(t)}"
        assert (
            t.device == x.device
        ), f"Expected tensors to be on {x.device}, got {t.device}"

        # if size_range is None:
        #     assert t.size() == x.size(), f'Expected tensors with same size, got {t.size()} and {x.size()}'
        # else:
        #     assert t.size()[size_range[0]: size_range[1]] == x.size()[size_range[0]: size_range[1]], \
        #         f'Expected tensors with same size at given dimensions, got {t.size()} and {x.size()}'

        if dim_range[0] == dim_range[1]:
            assert (
                t.dim() == dim_range[0]
            ), f"Expected number of dimensions to be {dim_range[0]}, got {t.dim()}"
        elif dim_range[0] < dim_range[1]:
            assert (
                dim_range[0] <= t.dim() <= dim_range[1]
            ), f"Expected number of dimensions to be between {dim_range[0]} and {dim_range[1]}, got {t.dim()}"

        if data_range[0] < data_range[1]:
            assert (
                data_range[0] <= t.min()
            ), f"Expected values to be greater or equal to {data_range[0]}, got {t.min()}"
            assert (
                t.max() <= data_range[1]
            ), f"Expected values to be lower or equal to {data_range[1]}, got {t.max()}"

        if check_for_channels_first:
            channels_last = t.shape[-1] in {1, 2, 3}
            assert (
                not channels_last
            ), "Expected tensor to have channels first format, but got channels last. \
                Please permute channels (e.g. t.permute(0, 3, 1, 2) for 4D tensors) and rerun."
