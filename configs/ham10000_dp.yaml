defaults:
  - base_config
  - _self_
project: ham10000
general:
  log_wandb: False
  parallel: False
  eval_train: True
  # save_path: 
  # make_save_str_unique: True
  use_pretrained_model: radimagenet_resnet9_gn_maxpool.npz
# ckpt:
#   logdir: _resnet9_ckpt
#   keep_ckpts: 10
#   makedir: True
dataset: 
  name: ham10000
  task: binary_classification
  root: ./data/dataverse_files
  train_val_split: 0.8
  test_split: 0.1
  ham:
    merge_labels: True
loader: 
  num_workers: 16
  prefetch_factor: 16
  collate_fn: numpy
  pin_memory: True
train_transforms:
  Resize: 
      size: 224
  RandomCrop:
      size: 224
  pil_to_numpy:
  numpy_img_to_chw:
test_transforms:
  Resize: 
      size: 224
  CenterCrop:
      size: 224
  pil_to_numpy:
  numpy_img_to_chw:
augmentations:
  normalize_jax:
      mean:
        - 0.7639
        - 0.5383
        - 0.5617
      std:
        - 0.1374
        - 0.1584
        - 0.1766
test_augmentations:
  normalize_jax:
      mean:
        - 0.7639
        - 0.5383
        - 0.5617
      std:
        - 0.1374
        - 0.1584
        - 0.1766
model:
  name: resnet9
  conv: conv
  in_channels: 1
  num_classes: 165
  activation: mish
  normalization: gn
  pooling: maxpool
  pretrained_model_changes:
    in_channels: 3
    num_classes: 1
    only_finetune: True
  # extra_args: 
  #   scale_norm: True
optim:
  name: nadam
ema:
  use_ema: True
  decay: 0.995
hyperparams:
  epochs: 50
  batch_size: 64
  batch_size_test: 128
  lr: 2e-3
  # overfit: 10
  # momentum: 0.9
metrics:
  main: 
    matthews_corrcoef:
  logging:
    classification_report:
      output_dict: True
      zero_division: 0
    accuracy_score: 
loss: 
  type: binary
  reduction: sum
scheduler:
  type: reduceonplateau
  normalize_lr: False
  patience: 5
  min_delta: 0.01
  factor: 0.9
earlystopping:
  mode: maximize
  patience: 100
  min_delta: 0.01
DP:
  epsilon: 8.0
  max_per_sample_grad_norm: 1.0
  delta: 8e-7
  norm_acc: False
  grad_acc_steps: 1