project: cifar-DP
general:
  log_wandb: False
  parallel: False
  eval_train: True
dataset: 
  name: CIFAR10
  root: ./data
  train_val_split: 0.9
  normalization: True
  fft: False
loader: 
  num_workers: 32
  prefetch_factor: 32
  collate_fn: numpy
augmentations:
  # consecutive_augmentations:
  #   multiplicity: 16
  #   consecutive_augmentations:
  #     random_img_shift:
  #       max_shift: 4
  #     random_vertical_flips:
  #       flip_prob: 0.5
model:
  name: resnet9
  in_channels: 3
  num_classes: 10
  conv: convws_nw
  activation: mish
  normalization: gn
  pooling: avgpool
  scale_norm: True
  ensemble: 2
optim:
  name: nadam
loss: 
  type: cse
  reduction: sum
ema:
  use_ema: True
  decay: 0.04
hyperparams:
  epochs: 200
  batch_size: 16
  batch_size_test: 512
  lr: 2e-3
  # momentum: 0.9
scheduler:
  type: reduceonplateau
  normalize_lr: False
  patience: 20
  min_delta: 0.01
  factor: 0.5
# earlystopping:
#   mode: maximize
#   patience: 100
#   min_delta: 0.01
DP:
  disable_dp: False
  epsilon: 7.5
  max_per_sample_grad_norm: 1.0
  delta: 1e-5
  norm_acc: False
  grad_acc_steps: 16
  adapt_noise: True