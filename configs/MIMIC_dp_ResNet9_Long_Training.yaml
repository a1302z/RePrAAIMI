project: MIMIC-DP-LONG
general:
  log_wandb: False
  parallel: False
  eval_train: True
dataset: 
  name: mimic
  root: 
    img: /data0/practical-wise2223/largescaledp/physionet.org/files/mimic-cxr-jpg/2.0.0/files
    csv: /data0/practical-wise2223/largescaledp/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-2.0.0-chexpert.csv.gz
    meta: /data0/practical-wise2223/largescaledp/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-2.0.0-metadata.csv.gz
  normalization: True
  fft: False
loader: 
  num_workers: 16
  prefetch_factor: 32
  collate_fn: numpy
augmentations:
  consecutive_augmentations:
    multiplicity: 16
    consecutive_augmentations:
      random_img_shift:
        max_shift: 4
      random_vertical_flips:
        flip_prob: 0.5
model:
  name: resnet9
  in_channels: 1
  num_classes: 13
  conv: convws_nw
  activation: mish
  normalization: gn
  pooling: avgpool
  scale_norm: True
optim:
  name: nadam
loss: 
  type: cse
  reduction: sum
ema:
  use_ema: True
  decay: 0.04
hyperparams:
  epochs: 70
  batch_size: 32
  batch_size_test: 256
  lr: 2e-3
  # momentum: 0.9
scheduler:
  type: reduceonplateau
  normalize_lr: False
  patience: 15
  min_delta: 0.01
  factor: 0.84
# earlystopping:
#   mode: maximize
#   patience: 100
#   min_delta: 0.01
DP:
  disable_dp: False
  epsilon: 7.5
  max_per_sample_grad_norm: 1.0
  delta: 3e-7
  norm_acc: False
  grad_acc_steps: 64
