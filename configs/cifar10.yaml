defaults:
  - base_config
  - _self_
general:
  log_wandb: False
  parallel: False
  eval_train: True
wandb:
  project: cifar
dataset: 
  task: classification
  name: CIFAR10
  root: ./data
  train_val_split: 0.9
  normalization: True
metrics:
  main: 
    accuracy_score: 
  logging:
    classification_report:
      output_dict: True
      zero_division: 0
loader: 
  num_workers: 16
  prefetch_factor: 16
  collate_fn: numpy
# augmentations:
# test_augmentations:
model:
  complex: False
  name: mlp
  activation: elu
  extra_args:
    sizes: 
      - 100
    inp_size: 3072
    outp_size: 10
optim:
  name: nadam
loss: 
  type: cse
  reduction: sum
  binary_loss: False
ema:
  use_ema: True
  decay: 0.995
hyperparams:
  epochs: 50
  batch_size: 512
  batch_size_test: 512
  lr: 2e-3
  # momentum: 0.9
  grad_acc_steps: 2
scheduler:
  type: reduceonplateau
  normalize_lr: False
  patience: 5
  min_delta: 0.01
  factor: 0.9
earlystopping:
  mode: maximize
  patience: 100
  min_delta: 0.01
