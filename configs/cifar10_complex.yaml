defaults:
  - base_config
  - _self_
general:
  log_wandb: False
  parallel: False
  eval_train: True
wandb:
  project: cifar-complex
dataset: 
  task: classification
  name: CIFAR10
  root: ./data
  train_val_split: 0.9
  fft: False
  normalization: True
metrics:
  main: 
    accuracy_score: 
  logging:
    classification_report:
      output_dict: True
      zero_division: 0
loader: 
  num_workers: 16
  prefetch_factor: 16
  collate_fn: numpy
augmentations:
  make_complex_both:
  random_augmentations:
    - consecutive_augmentations:
        complex: True
        augmentations:
          random_horizontal_flips: # identity
            flip_prob: 0
    - consecutive_augmentations:
        complex: True
        augmentations:
          random_horizontal_flips:
            flip_prob: 1.0
    - consecutive_augmentations:
        complex: True
        augmentations:
          random_vertical_flips:
            flip_prob: 1.0
    - consecutive_augmentations:
        complex: True
        augmentations:
          random_horizontal_flips:
            flip_prob: 0.5
    - consecutive_augmentations:
        complex: True
        augmentations:
          random_vertical_flips:
            flip_prob: 0.5
    - consecutive_augmentations:
        complex: True
        augmentations:
          random_img_shift:
            max_shift: 4
    - consecutive_augmentations:
        complex: True
        augmentations:
          random_img_shift:
            max_shift: 8
    - consecutive_augmentations:
        complex: True
        augmentations:
          random_horizontal_flips:
            flip_prob: 0.1
          random_vertical_flips:
            flip_prob: 0.1
          random_img_shift:
            max_shift: 4
test_augmentations:
  make_complex_both:
model:
  complex: True
  name: resnet9
  in_channels: 3
  num_classes: 10
  conv: convws_nw
  activation: conjmish
  normalization: bn
  pooling: avgpool
  extra_args:
    scale_norm: True
optim:
  name: nadam
loss: 
  type: cse
  reduction: mean
  binary_loss: False
ema:
  use_ema: False
  decay: 0.999
hyperparams:
  epochs: 100
  batch_size: 2048
  batch_size_test: 512
  lr: 2e-3
  # momentum: 0.9
  l2regularization: 1e-5
scheduler:
  type: reduceonplateau
  normalize_lr: False
  patience: 20
  min_delta: 0.01
  factor: 0.5
# earlystopping:
#   mode: maximize
#   patience: 100
#   min_delta: 0.01
